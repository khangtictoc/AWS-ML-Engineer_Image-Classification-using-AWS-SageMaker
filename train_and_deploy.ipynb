{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Title\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of these the TODO's and use more than one TODO code cell to do all your tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install packages for Debugging and Profiling on SageMaker\n",
    "# 'smdebug' may have error with latest version, so we should use another version.\n",
    "# Reference: https://pypi.org/project/smdebug/#history\n",
    "!pip install -U torch torchvision\n",
    "!pip install -U smdebug==1.0.3\n",
    "!pip install -U seaborn plotly opencv-python shap imageio bokeh\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure AWS Credential by \"environment variable\" or edit \"~/.aws/credentials\" or \"aws configure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\tranh\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n",
      "[2024-05-28 22:11:25.515 MYSHITDESKTOP:26356 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n"
     ]
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(null);\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {throw error;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(null);\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {throw error;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(null);\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {throw error;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import any packages that you might need\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.debugger import (\n",
    "    Rule, ProfilerRule, rule_configs,\n",
    "    DebuggerHookConfig, CollectionConfig,\n",
    "    ProfilerConfig, FrameworkProfile, \n",
    ")\n",
    "\n",
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Settings\n",
    "role = \"arn:aws:iam::028609567580:role/project03-khangtictoc\"\n",
    "region = \"us-east-1\"\n",
    "\n",
    "bucket = \"project03-khangtictoc\"\n",
    "prefix = \"dataset\"\n",
    "\n",
    "# debugger_s3_output = \"s3://{}/debugger-output\".format(bucket)\n",
    "# profiler_s3_output = \"s3://{}/profiler-output\".format(bucket)\n",
    "local_dataset_path = \"./dataset/dogImages\"\n",
    "\n",
    "image_name = \"resnet50-training-job\"\n",
    "ecr_name = \"public.ecr.aws/q1p8o7w7/resnet50-training-job:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create channel for data input's location\n",
    "train_loc = \"s3://project03-khangtictoc/dataset/train\"\n",
    "validation_loc = \"s3://project03-khangtictoc/dataset/valid\"\n",
    "test_loc = \"s3://project03-khangtictoc/dataset/test\"\n",
    "\n",
    "channels = {\n",
    "    \"training\": train_loc,\n",
    "    \"validation\": validation_loc,\n",
    "    \"testing\": test_loc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "TODO: Explain what dataset you are using for this project. Maybe even give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understand of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and sync to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (OperationAborted) when calling the CreateBucket operation: A conflicting conditional operation is currently in progress against this resource. Please try again.\n"
     ]
    }
   ],
   "source": [
    "!aws s3api create-bucket --bucket project03-khangtictoc --region us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and upload the data to AWS S3\n",
    "\n",
    "# Command to download and unzip data\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip dogImages.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal error: An error occurred (NoSuchBucket) when calling the ListObjectsV2 operation: The specified bucket does not exist\n",
      "fatal error: An error occurred (NoSuchBucket) when calling the ListObjectsV2 operation: The specified bucket does not exist\n",
      "fatal error: An error occurred (NoSuchBucket) when calling the ListObjectsV2 operation: The specified bucket does not exist\n"
     ]
    }
   ],
   "source": [
    "#!aws s3api create-bucket --bucket %DEFAULT_S3_BUCKET%\n",
    "\n",
    "# Window\n",
    "!aws s3 sync ./dataset/dogImages/train/ s3://{bucket}/dataset/train/\n",
    "!aws s3 sync ./dataset/dogImages/test/ s3://{bucket}/dataset/test/\n",
    "!aws s3 sync ./dataset/dogImages/valid/ s3://{bucket}/dataset/valid/\n",
    "\n",
    "# Linux\n",
    "#!aws s3 sync ./dataset/train s3://${DEFAULT_S3_BUCKET}/train/\n",
    "#!aws s3 sync ./dataset/test s3://${DEFAULT_S3_BUCKET}/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader (Optional)\n",
    "\n",
    "Use local workspace for investigating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define transforming actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.ImageFolder(\"./dataset/dogImages/train\", transform=transforms)\n",
    "valset = datasets.ImageFolder(\"./dataset/dogImages/valid\", transform=transforms)\n",
    "testset = datasets.ImageFolder(\"./dataset/dogImages/test\", transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001.Affenpinscher',\n",
       " '002.Afghan_hound',\n",
       " '003.Airedale_terrier',\n",
       " '004.Akita',\n",
       " '005.Alaskan_malamute']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show labels\n",
    "train_loader.dataset.classes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./dataset/dogImages/train\\\\129.Tibetan_mastiff\\\\Tibetan_mastiff_08184.jpg',\n",
       "  128),\n",
       " ('./dataset/dogImages/train\\\\025.Black_and_tan_coonhound\\\\Black_and_tan_coonhound_01781.jpg',\n",
       "  24),\n",
       " ('./dataset/dogImages/train\\\\091.Japanese_chin\\\\Japanese_chin_06201.jpg', 90),\n",
       " ('./dataset/dogImages/train\\\\104.Miniature_schnauzer\\\\Miniature_schnauzer_06887.jpg',\n",
       "  103),\n",
       " ('./dataset/dogImages/train\\\\094.Komondor\\\\Komondor_06353.jpg', 93)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View some samples and labels\n",
    "random_img = random.sample(train_loader.dataset.imgs, 5)\n",
    "random_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File extensions\n",
    "train_loader.dataset.extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 133\n",
      "Number of samples: 6680\n"
     ]
    }
   ],
   "source": [
    "# Number of labels\n",
    "print(\"Number of labels: %d\" % len(train_loader.dataset.classes))\n",
    "\n",
    "# Number of samples\n",
    "print(\"Number of samples: %d\" % len(train_loader.dataset.imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "TODO: This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "Note: You will need to use the hpo.py script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare HP ranges, metrics etc.\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([16, 32, 64, 128, 256, 512]),\n",
    "    \"epochs\": IntegerParameter(10, 20)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \"Regex\": \"Test set: Average loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimators for HPs\n",
    "\n",
    "estimator = PyTorch(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"hpo.py\",\n",
    "    framework_version=\"2.2\",\n",
    "    py_version=\"py310\",\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=1,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# Fit HP Tuner\n",
    "tuner.fit(inputs=channels, wait=True) # Include data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-05-27 23:35:14 Starting - Found matching resource for reuse\n",
      "2024-05-27 23:35:14 Downloading - Downloading the training image\n",
      "2024-05-27 23:35:14 Training - Training image download completed. Training in progress.\n",
      "2024-05-27 23:35:14 Uploading - Uploading generated training model\n",
      "2024-05-27 23:35:14 Completed - Resource released due to keep alive period expiry\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimators and the best HPs\n",
    "best_estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"average test loss\"',\n",
       " 'batch-size': '\"256\"',\n",
       " 'epochs': '16',\n",
       " 'lr': '0.004909233792902113',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch-training-2024-05-27-17-21-30-757\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-028609567580/pytorch-training-2024-05-27-17-21-30-757/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': '0.004909233792902113', 'batch-size': 256, 'epochs': '16'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create hyperparameter dict for the best model for later use\n",
    "best_hyperparameters = {\n",
    "    \"lr\": best_estimator.hyperparameters()['lr'],\n",
    "    \"batch-size\": int(best_estimator.hyperparameters()['batch-size'].replace('\"', '')),\n",
    "    \"epochs\": int(best_estimator.hyperparameters()['epochs'])\n",
    "}\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "Note: You will need to use the train_model.py script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_configs=[\n",
    "    CollectionConfig(\n",
    "        name=\"CrossEntopyLoss_output_0\",\n",
    "        parameters={\n",
    "            \"include_regex\": \"CrossEntropyLoss_output_0\",\n",
    "            \"train.save_interval\": \"1\",\n",
    "            \"eval.save_interval\": \"1\"\n",
    "        }\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Debugger\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    #s3_output_path=debugger_s3_output,\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"100\",\n",
    "        \"eval.save_interval\": \"10\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:Framework profiling will be deprecated from tensorflow 2.12 and pytorch 2.0 in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Configure Profiler\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(num_steps=10),\n",
    "    #s3_output_path=profiler_s3_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the rules for debugging\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-05-28-13-38-08-788\n"
     ]
    }
   ],
   "source": [
    "# Create and fit an estimator\n",
    "\n",
    "estimator = PyTorch(\n",
    "    role=role,\n",
    "\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.4xlarge\",\n",
    "\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"train_model.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters={'lr': '0.004909233792902113', 'batch-size': 256, 'epochs': 16},\n",
    "\n",
    "    rules=rules,\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    profiler_config=profiler_config\n",
    ")\n",
    "\n",
    "estimator.fit(inputs=channels, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a debugging output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync  s3://sagemaker-us-east-1-028609567580/pytorch-training-2024-05-28-08-35-06-969/ ./training-job/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training jobname: pytorch-training-2024-05-28-08-35-06-969\n",
      "Region: us-east-1\n",
      "ProfilerConfig:{'S3OutputPath': 's3://sagemaker-us-east-1-028609567580/', 'ProfilingIntervalInMilliseconds': 500, 'ProfilingParameters': {'DataloaderProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, \"MetricsRegex\": \".*\", }', 'DetailedProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }', 'FileOpenFailThreshold': '50', 'HorovodProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }', 'LocalPath': '/opt/ml/output/profiler', 'PythonProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, \"ProfilerName\": \"cprofile\", \"cProfileTimer\": \"total_time\", }', 'RotateFileCloseIntervalInSeconds': '60', 'RotateMaxFileSizeInBytes': '10485760', 'SMDataParallelProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }'}, 'DisableProfiler': False}\n",
      "s3 path:s3://sagemaker-us-east-1-028609567580/pytorch-training-2024-05-28-08-35-06-969\\profiler-output\n"
     ]
    }
   ],
   "source": [
    "training_job_name = \"pytorch-training-2024-05-28-08-35-06-969\" #estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")\n",
    "tj = TrainingJob(training_job_name, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfilerConfig:{'S3OutputPath': 's3://sagemaker-us-east-1-028609567580/', 'ProfilingIntervalInMilliseconds': 500, 'ProfilingParameters': {'DataloaderProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, \"MetricsRegex\": \".*\", }', 'DetailedProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }', 'FileOpenFailThreshold': '50', 'HorovodProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }', 'LocalPath': '/opt/ml/output/profiler', 'PythonProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, \"ProfilerName\": \"cprofile\", \"cProfileTimer\": \"total_time\", }', 'RotateFileCloseIntervalInSeconds': '60', 'RotateMaxFileSizeInBytes': '10485760', 'SMDataParallelProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }'}, 'DisableProfiler': False}\n",
      "s3 path:s3://sagemaker-us-east-1-028609567580/pytorch-training-2024-05-28-08-35-06-969\\profiler-output\n",
      "Profiler data from system not available yet\n",
      "time: 1716909713.464636 TrainingJobStatus:Completed TrainingJobSecondaryStatus:Completed\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n",
      "Profiler data from system not available yet\n"
     ]
    }
   ],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(\"./training-job\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trial.tensor_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trial.tensor(\"CrossEntropyLoss_output_0\").steps(mode=ModeKeys.TRAIN)))\n",
    "print(len(trial.tensor(\"CrossEntropyLoss_output_0\").steps(mode=ModeKeys.EVAL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"You will find the profiler report in {rule_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy your model to an endpoint\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Affenpinscher',\n",
       " 1: 'Afghan_hound',\n",
       " 2: 'Airedale_terrier',\n",
       " 3: 'Akita',\n",
       " 4: 'Alaskan_malamute',\n",
       " 5: 'American_eskimo_dog',\n",
       " 6: 'American_foxhound',\n",
       " 7: 'American_staffordshire_terrier',\n",
       " 8: 'American_water_spaniel',\n",
       " 9: 'Anatolian_shepherd_dog',\n",
       " 10: 'Australian_cattle_dog',\n",
       " 11: 'Australian_shepherd',\n",
       " 12: 'Australian_terrier',\n",
       " 13: 'Basenji',\n",
       " 14: 'Basset_hound',\n",
       " 15: 'Beagle',\n",
       " 16: 'Bearded_collie',\n",
       " 17: 'Beauceron',\n",
       " 18: 'Bedlington_terrier',\n",
       " 19: 'Belgian_malinois',\n",
       " 20: 'Belgian_sheepdog',\n",
       " 21: 'Belgian_tervuren',\n",
       " 22: 'Bernese_mountain_dog',\n",
       " 23: 'Bichon_frise',\n",
       " 24: 'Black_and_tan_coonhound',\n",
       " 25: 'Black_russian_terrier',\n",
       " 26: 'Bloodhound',\n",
       " 27: 'Bluetick_coonhound',\n",
       " 28: 'Border_collie',\n",
       " 29: 'Border_terrier',\n",
       " 30: 'Borzoi',\n",
       " 31: 'Boston_terrier',\n",
       " 32: 'Bouvier_des_flandres',\n",
       " 33: 'Boxer',\n",
       " 34: 'Boykin_spaniel',\n",
       " 35: 'Briard',\n",
       " 36: 'Brittany',\n",
       " 37: 'Brussels_griffon',\n",
       " 38: 'Bull_terrier',\n",
       " 39: 'Bulldog',\n",
       " 40: 'Bullmastiff',\n",
       " 41: 'Cairn_terrier',\n",
       " 42: 'Canaan_dog',\n",
       " 43: 'Cane_corso',\n",
       " 44: 'Cardigan_welsh_corgi',\n",
       " 45: 'Cavalier_king_charles_spaniel',\n",
       " 46: 'Chesapeake_bay_retriever',\n",
       " 47: 'Chihuahua',\n",
       " 48: 'Chinese_crested',\n",
       " 49: 'Chinese_shar-pei',\n",
       " 50: 'Chow_chow',\n",
       " 51: 'Clumber_spaniel',\n",
       " 52: 'Cocker_spaniel',\n",
       " 53: 'Collie',\n",
       " 54: 'Curly-coated_retriever',\n",
       " 55: 'Dachshund',\n",
       " 56: 'Dalmatian',\n",
       " 57: 'Dandie_dinmont_terrier',\n",
       " 58: 'Doberman_pinscher',\n",
       " 59: 'Dogue_de_bordeaux',\n",
       " 60: 'English_cocker_spaniel',\n",
       " 61: 'English_setter',\n",
       " 62: 'English_springer_spaniel',\n",
       " 63: 'English_toy_spaniel',\n",
       " 64: 'Entlebucher_mountain_dog',\n",
       " 65: 'Field_spaniel',\n",
       " 66: 'Finnish_spitz',\n",
       " 67: 'Flat-coated_retriever',\n",
       " 68: 'French_bulldog',\n",
       " 69: 'German_pinscher',\n",
       " 70: 'German_shepherd_dog',\n",
       " 71: 'German_shorthaired_pointer',\n",
       " 72: 'German_wirehaired_pointer',\n",
       " 73: 'Giant_schnauzer',\n",
       " 74: 'Glen_of_imaal_terrier',\n",
       " 75: 'Golden_retriever',\n",
       " 76: 'Gordon_setter',\n",
       " 77: 'Great_dane',\n",
       " 78: 'Great_pyrenees',\n",
       " 79: 'Greater_swiss_mountain_dog',\n",
       " 80: 'Greyhound',\n",
       " 81: 'Havanese',\n",
       " 82: 'Ibizan_hound',\n",
       " 83: 'Icelandic_sheepdog',\n",
       " 84: 'Irish_red_and_white_setter',\n",
       " 85: 'Irish_setter',\n",
       " 86: 'Irish_terrier',\n",
       " 87: 'Irish_water_spaniel',\n",
       " 88: 'Irish_wolfhound',\n",
       " 89: 'Italian_greyhound',\n",
       " 90: 'Japanese_chin',\n",
       " 91: 'Keeshond',\n",
       " 92: 'Kerry_blue_terrier',\n",
       " 93: 'Komondor',\n",
       " 94: 'Kuvasz',\n",
       " 95: 'Labrador_retriever',\n",
       " 96: 'Lakeland_terrier',\n",
       " 97: 'Leonberger',\n",
       " 98: 'Lhasa_apso',\n",
       " 99: 'Lowchen',\n",
       " 100: 'Maltese',\n",
       " 101: 'Manchester_terrier',\n",
       " 102: 'Mastiff',\n",
       " 103: 'Miniature_schnauzer',\n",
       " 104: 'Neapolitan_mastiff',\n",
       " 105: 'Newfoundland',\n",
       " 106: 'Norfolk_terrier',\n",
       " 107: 'Norwegian_buhund',\n",
       " 108: 'Norwegian_elkhound',\n",
       " 109: 'Norwegian_lundehund',\n",
       " 110: 'Norwich_terrier',\n",
       " 111: 'Nova_scotia_duck_tolling_retriever',\n",
       " 112: 'Old_english_sheepdog',\n",
       " 113: 'Otterhound',\n",
       " 114: 'Papillon',\n",
       " 115: 'Parson_russell_terrier',\n",
       " 116: 'Pekingese',\n",
       " 117: 'Pembroke_welsh_corgi',\n",
       " 118: 'Petit_basset_griffon_vendeen',\n",
       " 119: 'Pharaoh_hound',\n",
       " 120: 'Plott',\n",
       " 121: 'Pointer',\n",
       " 122: 'Pomeranian',\n",
       " 123: 'Poodle',\n",
       " 124: 'Portuguese_water_dog',\n",
       " 125: 'Saint_bernard',\n",
       " 126: 'Silky_terrier',\n",
       " 127: 'Smooth_fox_terrier',\n",
       " 128: 'Tibetan_mastiff',\n",
       " 129: 'Welsh_springer_spaniel',\n",
       " 130: 'Wirehaired_pointing_griffon',\n",
       " 131: 'Xoloitzcuintli',\n",
       " 132: 'Yorkshire_terrier'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary for class-to-label mapping\n",
    "\n",
    "test_path = os.path.join(local_dataset_path, \"test\")\n",
    "\n",
    "label_breed_mapping = {k:v.split(\".\")[1] for k, v in enumerate(os.listdir(test_path))}\n",
    "label_breed_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an prediction on the endpoint\n",
    "\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "\n",
    "test_folder = \"012.Australian_shepherd\"\n",
    "test_image = \"Australian_shepherd_00830.jpg\"\n",
    "\n",
    "with open(os.path.join(test_path, test_folder, test_image), \"rb\") as f:\n",
    "    image = f.read()\n",
    "response = predictor.predict(image)\n",
    "\n",
    "print(\"Expected label: \\\"{}\\\" with  index of {}\".format(\n",
    "      test_folder.split(\".\")[1],\n",
    "      test_folder.split(\".\")[0]))\n",
    "print(\"Predicted label: \\\"{}\\\" with index of {}\".format(\n",
    "    response,\n",
    "    label_breed_mapping[response]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IIPORTANT) Shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up remote registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_client = boto3.client(\"ecr\")\n",
    "ecr_response = ecr_client.create_repository(repositoryName=\"only-test\")\n",
    "ecr_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr-public::008748484958:repository/resnet50-training-job\",\n",
      "        \"registryId\": \"008748484958\",\n",
      "        \"repositoryName\": \"resnet50-training-job\",\n",
      "        \"repositoryUri\": \"public.ecr.aws/q1p8o7w7/resnet50-training-job\",\n",
      "        \"createdAt\": \"2024-05-24T15:42:19.395000+07:00\"\n",
      "    },\n",
      "    \"catalogData\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create ECR Repository if not exists\n",
    "!aws ecr-public create-repository --repository-name {image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in C:\\Users\\tranh\\.docker\\config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Authenticate AWS ECR\n",
    "# Push command on Console\n",
    "#!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
    "!aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/q1p8o7w7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload image to registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package training model to Docker Image\n",
    "!docker build -t {image_name} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [public.ecr.aws/q1p8o7w7/resnet50-training-job]\n",
      "bbe00fe64b55: Preparing\n",
      "9501e9fcc404: Preparing\n",
      "1c4281c1b467: Preparing\n",
      "8f3dd49b5d19: Preparing\n",
      "555315c92a50: Preparing\n",
      "3be02ac4f30b: Preparing\n",
      "4a36b0c85768: Preparing\n",
      "6addedefeb30: Preparing\n",
      "f21b8e6382b2: Preparing\n",
      "3be02ac4f30b: Waiting\n",
      "4a36b0c85768: Waiting\n",
      "6addedefeb30: Waiting\n",
      "f21b8e6382b2: Waiting\n",
      "a1c8c36e3146: Preparing\n",
      "a1c8c36e3146: Waiting\n",
      "88c6b56a015e: Preparing\n",
      "d4c2f7022d7b: Preparing\n",
      "88c6b56a015e: Waiting\n",
      "d4c2f7022d7b: Waiting\n",
      "37d54eb19c68: Preparing\n",
      "e7c49386baa5: Preparing\n",
      "37d54eb19c68: Waiting\n",
      "e7c49386baa5: Waiting\n",
      "6723bb391f86: Preparing\n",
      "2b77c1837fdd: Preparing\n",
      "c308ea0f2bb6: Preparing\n",
      "91e1df25c605: Preparing\n",
      "72b51d6d1d55: Preparing\n",
      "90dfc325730b: Preparing\n",
      "ef7f8b990cf9: Preparing\n",
      "454df595b059: Preparing\n",
      "078266e4cb4c: Preparing\n",
      "fb99a34a5b47: Preparing\n",
      "6723bb391f86: Waiting\n",
      "454df595b059: Waiting\n",
      "2b77c1837fdd: Waiting\n",
      "91e1df25c605: Waiting\n",
      "72b51d6d1d55: Waiting\n",
      "90dfc325730b: Waiting\n",
      "c308ea0f2bb6: Waiting\n",
      "078266e4cb4c: Waiting\n",
      "fb99a34a5b47: Waiting\n",
      "ef7f8b990cf9: Waiting\n",
      "79c3fd430d0b: Preparing\n",
      "4a1518ebc26e: Preparing\n",
      "79c3fd430d0b: Waiting\n",
      "4a1518ebc26e: Waiting\n",
      "8f3dd49b5d19: Layer already exists\n",
      "555315c92a50: Layer already exists\n",
      "1c4281c1b467: Layer already exists\n",
      "3be02ac4f30b: Layer already exists\n",
      "4a36b0c85768: Layer already exists\n",
      "6addedefeb30: Layer already exists\n",
      "f21b8e6382b2: Layer already exists\n",
      "88c6b56a015e: Layer already exists\n",
      "a1c8c36e3146: Layer already exists\n",
      "d4c2f7022d7b: Layer already exists\n",
      "37d54eb19c68: Layer already exists\n",
      "e7c49386baa5: Layer already exists\n",
      "bbe00fe64b55: Pushed\n",
      "6723bb391f86: Layer already exists\n",
      "2b77c1837fdd: Layer already exists\n",
      "c308ea0f2bb6: Layer already exists\n",
      "91e1df25c605: Layer already exists\n",
      "72b51d6d1d55: Layer already exists\n",
      "90dfc325730b: Layer already exists\n",
      "ef7f8b990cf9: Layer already exists\n",
      "454df595b059: Layer already exists\n",
      "fb99a34a5b47: Layer already exists\n",
      "078266e4cb4c: Layer already exists\n",
      "79c3fd430d0b: Layer already exists\n",
      "4a1518ebc26e: Pushed\n",
      "9501e9fcc404: Pushed\n",
      "latest: digest: sha256:684aafe8ed6d7bc5aafe47555dc3fff35d259398272fb4404afe7aee25ace543 size: 5783\n"
     ]
    }
   ],
   "source": [
    "# Re-tag images to remote ECR registry\n",
    "!docker tag {image_name}:latest public.ecr.aws/q1p8o7w7/{image_name}:latest\n",
    "# Push image to remote AWS ECR\n",
    "!docker push public.ecr.aws/q1p8o7w7/{image_name}:latest"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
