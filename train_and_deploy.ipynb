{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Title\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of these the TODO's and use more than one TODO code cell to do all your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install packages for Debugging and Profiling on SageMaker\n",
    "# 'smdebug' may have error with latest version, so we should use another version.\n",
    "## Reference: https://pypi.org/project/smdebug/#history\n",
    "!pip install -U smdebug==1.0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\ADMIN\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Import any packages that you might need\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.debugger import (\n",
    "    Rule, ProfilerRule, rule_configs,\n",
    "    DebuggerHookConfig, ProfilerConfig, FrameworkProfile\n",
    ")\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Settings\n",
    "bucket = \"project03-khangtictoc\"\n",
    "prefix = \"dataset\"\n",
    "role = \"arn:aws:iam::590714309454:role/project03-khangtictoc\"\n",
    "debugger_s3_output = \"s3://{}/debugger-output\".format(bucket)\n",
    "profiler_s3_output = \"s3://{}/profiler-output\".format(bucket)\n",
    "local_dataset_path = \"./dataset/dogImages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure credentials\n",
    "!aws configure set aws_access_key_id ASIAYTCKRBNHEZP5OT63\n",
    "!aws configure set aws_secret_access_key zms6J2llWGPN7+ZbC2wcD9ckVAfAVmyOSG083nMv\n",
    "!aws configure set aws_session_token IQoJb3JpZ2luX2VjEOf//////////wEaCXVzLXdlc3QtMiJHMEUCIATAIwQxgHOrawckNW5O9tmy6O5GV5cDQwj+2FLppFk1AiEA9+JE46DGKeFSMujraKCQ4EWQhRTe2VSBAYn/X5phUooqvgIIYBADGgw1OTA3MTQzMDk0NTQiDMuE2oR6NLp0dDjm6yqbAiQbwGMKrcZrABmlgUqv+NpO25c0f5C4/eAg/A6I325LT7JMVGwCNH/7UmqFPYUTEF6i5/Ntfirn7pNwSatH+o3TWfNrqkN8gfE4XJAL0VvQRQGL0pPRefShamMvb1F6G/3UXZtRCHSg6gCf/umX5PnE76QTLEWKMBA1WcfWqlwfHsehoc1ObfpQ/OL1Jtu94UPXpKuC1XCLKJNxh0OYYVHBBW9ZpSWQmuOe3Qx5Y3TJhZAdg30ZL2QsVpR4gG/cBVKloXapsVXhj+hinjLLt+ywUVF5SWZovz9Y30kDI/yT5RtbZMQ6Obj3rT3/cKFwJBP/B1awF5IDb3j1rgTZueyfeGPzp6DKKyvWfmGjXrx9Gx8tRly5Q5L4k9kw6IG4sgY6nQFTX1CS+0WDK3vsBfYegIHyOt5n65J636y7q0/D3mmnoKSyZqxxWL09OkpeGe+H3n/nCgc4SF5dQCVyhdODhukzeyEdoRcJ4LBSUOEfzws1Bh6liK0Lcg/J8P1keIwNrpUpYnHjrTKJcFiScUy6eEdvQpXMD6312QttV0BD34Aiov1mK9NH/7ehmqRJJB8YnvhLkEfDJYW93PbI+m4G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "TODO: Explain what dataset you are using for this project. Maybe even give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understand of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and sync to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and upload the data to AWS S3\n",
    "\n",
    "# Command to download and unzip data\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip dogImages.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] = bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3api create-bucket --bucket %DEFAULT_S3_BUCKET%\n",
    "\n",
    "# Window\n",
    "!aws s3 sync ./dataset/dogImages/train/ s3://%DEFAULT_S3_BUCKET%/dataset/train/\n",
    "!aws s3 sync ./dataset/dogImages/test/ s3://%DEFAULT_S3_BUCKET%/dataset/test/\n",
    "!aws s3 sync ./dataset/dogImages/valid/ s3://%DEFAULT_S3_BUCKET%/dataset/valid/\n",
    "\n",
    "# Linux\n",
    "#!aws s3 sync ./dataset/train s3://${DEFAULT_S3_BUCKET}/train/\n",
    "#!aws s3 sync ./dataset/test s3://${DEFAULT_S3_BUCKET}/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader (Optional)\n",
    "\n",
    "Use local workspace for investigating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define transforming actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.ImageFolder(\"./dataset/dogImages/train\", transform=transforms)\n",
    "valset = datasets.ImageFolder(\"./dataset/dogImages/valid\", transform=transforms)\n",
    "testset = datasets.ImageFolder(\"./dataset/dogImages/test\", transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001.Affenpinscher',\n",
       " '002.Afghan_hound',\n",
       " '003.Airedale_terrier',\n",
       " '004.Akita',\n",
       " '005.Alaskan_malamute']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show labels\n",
    "train_loader.dataset.classes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./dataset/dogImages/train\\\\129.Tibetan_mastiff\\\\Tibetan_mastiff_08184.jpg',\n",
       "  128),\n",
       " ('./dataset/dogImages/train\\\\025.Black_and_tan_coonhound\\\\Black_and_tan_coonhound_01781.jpg',\n",
       "  24),\n",
       " ('./dataset/dogImages/train\\\\091.Japanese_chin\\\\Japanese_chin_06201.jpg', 90),\n",
       " ('./dataset/dogImages/train\\\\104.Miniature_schnauzer\\\\Miniature_schnauzer_06887.jpg',\n",
       "  103),\n",
       " ('./dataset/dogImages/train\\\\094.Komondor\\\\Komondor_06353.jpg', 93)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View some samples and labels\n",
    "random_img = random.sample(train_loader.dataset.imgs, 5)\n",
    "random_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File extensions\n",
    "train_loader.dataset.extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 133\n",
      "Number of samples: 6680\n"
     ]
    }
   ],
   "source": [
    "# Number of labels\n",
    "print(\"Number of labels: %d\" % len(train_loader.dataset.classes))\n",
    "\n",
    "# Number of samples\n",
    "print(\"Number of samples: %d\" % len(train_loader.dataset.imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "TODO: This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "Note: You will need to use the hpo.py script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare HP ranges, metrics etc.\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([16, 32, 64, 128, 256, 512]),\n",
    "    \"epochs\": IntegerParameter(10, 20)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \"Regex\": \"Test set: Average loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimators for HPs\n",
    "\n",
    "estimator = PyTorch(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"hpo.py\",\n",
    "    framework_version=\"2.2\",\n",
    "    py_version=\"py310\",\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=1,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create channel for data input's location\n",
    "train_loc = \"s3://project03-khangtictoc/dataset/train\"\n",
    "validation_loc = \"s3://project03-khangtictoc/dataset/valid\"\n",
    "test_loc = \"s3://project03-khangtictoc/dataset/test\"\n",
    "\n",
    "channels = {\n",
    "    \"training\": train_loc,\n",
    "    \"validation\": validation_loc,\n",
    "    \"testing\": test_loc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# Fit HP Tuner\n",
    "tuner.fit(inputs=channels, wait=True) # Include data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-05-22 14:50:22 Starting - Found matching resource for reuse\n",
      "2024-05-22 14:50:22 Downloading - Downloading the training image\n",
      "2024-05-22 14:50:22 Training - Training image download completed. Training in progress.\n",
      "2024-05-22 14:50:22 Uploading - Uploading generated training model\n",
      "2024-05-22 14:50:22 Completed - Resource reused by training job: pytorch-training-240522-2131-004-b6f473a7\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimators and the best HPs\n",
    "best_estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"average test loss\"',\n",
       " 'batch-size': '\"32\"',\n",
       " 'epochs': '12',\n",
       " 'lr': '0.06740352060079005',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch-training-2024-05-22-14-30-30-942\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-590714309454/pytorch-training-2024-05-22-14-30-30-942/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': '0.06740352060079005', 'batch-size': 32, 'epochs': '12'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create hyperparameter dict for the best model for later use\n",
    "best_hyperparameters = {\n",
    "    \"lr\": best_estimator.hyperparameters()['lr'],\n",
    "    \"batch-size\": int(best_estimator.hyperparameters()['batch-size'].replace('\"', '')),\n",
    "    \"epochs\": best_estimator.hyperparameters()['epochs']\n",
    "}\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "Note: You will need to use the train_model.py script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Debugger\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    s3_output_path=debugger_s3_output,\n",
    "    container_local_output_path=debugger_s3_output,\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"100\",\n",
    "        \"eval.save_interval\": \"10\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:Framework profiling will be deprecated from tensorflow 2.12 and pytorch 2.0 in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Configure Profiler\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(num_steps=10),\n",
    "    s3_output_path=profiler_s3_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the rules for debugging\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-05-22-15-49-05-241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 15:49:11 Starting - Starting the training job...\n",
      "2024-05-22 15:49:13 Pending - Training job waiting for capacity.........\n",
      "2024-05-22 15:51:19 Pending - Preparing the instances for training...\n",
      "2024-05-22 15:51:56 Downloading - Downloading input data......\n",
      "2024-05-22 15:52:49 Downloading - Downloading the training image...............\n",
      "2024-05-22 15:55:30 Training - Training image download completed. Training in progress.bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-05-22 15:55:51,943 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-05-22 15:55:51,959 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-05-22 15:55:51,975 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-05-22 15:55:51,977 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-05-22 15:55:53,594 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-05-22 15:55:53,647 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-05-22 15:55:53,678 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-05-22 15:55:53,691 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"epochs\": \"12\",\n",
      "        \"lr\": \"0.06740352060079005\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2024-05-22-15-49-05-241\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-590714309454/pytorch-training-2024-05-22-15-49-05-241/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch-size\":32,\"epochs\":\"12\",\"lr\":\"0.06740352060079005\"}\n",
      "SM_USER_ENTRY_POINT=train_model.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"testing\",\"training\",\"validation\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train_model\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-590714309454/pytorch-training-2024-05-22-15-49-05-241/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":\"12\",\"lr\":\"0.06740352060079005\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"pytorch-training-2024-05-22-15-49-05-241\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-590714309454/pytorch-training-2024-05-22-15-49-05-241/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model.py\"}\n",
      "SM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"12\",\"--lr\",\"0.06740352060079005\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TESTING=/opt/ml/input/data/testing\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "SM_HP_BATCH-SIZE=32\n",
      "SM_HP_EPOCHS=12\n",
      "SM_HP_LR=0.06740352060079005\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.10 train_model.py --batch-size 32 --epochs 12 --lr 0.06740352060079005\n",
      "2024-05-22 15:55:53,691 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "2024-05-22 15:55:53,691 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_model.py\", line 13, in <module>\n",
      "import smdebug.pytorch as smd\n",
      "ModuleNotFoundError: No module named 'smdebug'\n",
      "2024-05-22 15:55:56,233 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-05-22 15:55:56,233 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\n",
      "2024-05-22 15:55:56,234 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n",
      "2024-05-22 15:55:56,234 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "ExitCode 1\n",
      "ErrorMessage \"ModuleNotFoundError: No module named 'smdebug'\"\n",
      "Command \"/opt/conda/bin/python3.10 train_model.py --batch-size 32 --epochs 12 --lr 0.06740352060079005\"\n",
      "2024-05-22 15:55:56,234 sagemaker-training-toolkit ERROR    Encountered exit_code 1\n",
      "\n",
      "2024-05-22 15:56:13 Uploading - Uploading generated training model\n",
      "2024-05-22 15:56:13 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2024-05-22-15-49-05-241: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ModuleNotFoundError: No module named 'smdebug'\"\nCommand \"/opt/conda/bin/python3.10 train_model.py --batch-size 32 --epochs 12 --lr 0.06740352060079005\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create and fit an estimator\u001b[39;00m\n\u001b[0;32m      3\u001b[0m estimator \u001b[38;5;241m=\u001b[39m PyTorch(\n\u001b[0;32m      4\u001b[0m     role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[0;32m      5\u001b[0m     instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# profiler_config=profiler_config\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sagemaker\\workflow\\pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sagemaker\\estimator.py:1341\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[1;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sagemaker\\estimator.py:2680\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m   2678\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2680\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sagemaker\\session.py:5766\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[1;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[0;32m   5745\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   5746\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[0;32m   5747\u001b[0m \n\u001b[0;32m   5748\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5764\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[0;32m   5765\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5766\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sagemaker\\session.py:7995\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[1;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[0;32m   7992\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[0;32m   7994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m-> 7995\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7996\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[0;32m   7997\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sagemaker\\session.py:8048\u001b[0m, in \u001b[0;36m_check_job_status\u001b[1;34m(job, desc, status_key_name)\u001b[0m\n\u001b[0;32m   8042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[0;32m   8043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[0;32m   8044\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m   8045\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   8046\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[0;32m   8047\u001b[0m     )\n\u001b[1;32m-> 8048\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[0;32m   8049\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m   8050\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   8051\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[0;32m   8052\u001b[0m )\n",
      "\u001b[1;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2024-05-22-15-49-05-241: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ModuleNotFoundError: No module named 'smdebug'\"\nCommand \"/opt/conda/bin/python3.10 train_model.py --batch-size 32 --epochs 12 --lr 0.06740352060079005\", exit code: 1"
     ]
    }
   ],
   "source": [
    "# Create and fit an estimator\n",
    "\n",
    "estimator = PyTorch(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"train_model.py\",\n",
    "    framework_version=\"2.2\",\n",
    "    py_version=\"py310\",\n",
    "    hyperparameters=best_hyperparameters,\n",
    "    \n",
    "    \n",
    "    # rules=rules,\n",
    "    # debugger_hook_config=debugger_hook_config,\n",
    "    # profiler_config=profiler_config\n",
    ")\n",
    "\n",
    "estimator.fit(inputs=channels, wait=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a debugging output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Analyze Profiling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download Debugger Profiling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy your model to an endpoint\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Affenpinscher',\n",
       " 1: 'Afghan_hound',\n",
       " 2: 'Airedale_terrier',\n",
       " 3: 'Akita',\n",
       " 4: 'Alaskan_malamute',\n",
       " 5: 'American_eskimo_dog',\n",
       " 6: 'American_foxhound',\n",
       " 7: 'American_staffordshire_terrier',\n",
       " 8: 'American_water_spaniel',\n",
       " 9: 'Anatolian_shepherd_dog',\n",
       " 10: 'Australian_cattle_dog',\n",
       " 11: 'Australian_shepherd',\n",
       " 12: 'Australian_terrier',\n",
       " 13: 'Basenji',\n",
       " 14: 'Basset_hound',\n",
       " 15: 'Beagle',\n",
       " 16: 'Bearded_collie',\n",
       " 17: 'Beauceron',\n",
       " 18: 'Bedlington_terrier',\n",
       " 19: 'Belgian_malinois',\n",
       " 20: 'Belgian_sheepdog',\n",
       " 21: 'Belgian_tervuren',\n",
       " 22: 'Bernese_mountain_dog',\n",
       " 23: 'Bichon_frise',\n",
       " 24: 'Black_and_tan_coonhound',\n",
       " 25: 'Black_russian_terrier',\n",
       " 26: 'Bloodhound',\n",
       " 27: 'Bluetick_coonhound',\n",
       " 28: 'Border_collie',\n",
       " 29: 'Border_terrier',\n",
       " 30: 'Borzoi',\n",
       " 31: 'Boston_terrier',\n",
       " 32: 'Bouvier_des_flandres',\n",
       " 33: 'Boxer',\n",
       " 34: 'Boykin_spaniel',\n",
       " 35: 'Briard',\n",
       " 36: 'Brittany',\n",
       " 37: 'Brussels_griffon',\n",
       " 38: 'Bull_terrier',\n",
       " 39: 'Bulldog',\n",
       " 40: 'Bullmastiff',\n",
       " 41: 'Cairn_terrier',\n",
       " 42: 'Canaan_dog',\n",
       " 43: 'Cane_corso',\n",
       " 44: 'Cardigan_welsh_corgi',\n",
       " 45: 'Cavalier_king_charles_spaniel',\n",
       " 46: 'Chesapeake_bay_retriever',\n",
       " 47: 'Chihuahua',\n",
       " 48: 'Chinese_crested',\n",
       " 49: 'Chinese_shar-pei',\n",
       " 50: 'Chow_chow',\n",
       " 51: 'Clumber_spaniel',\n",
       " 52: 'Cocker_spaniel',\n",
       " 53: 'Collie',\n",
       " 54: 'Curly-coated_retriever',\n",
       " 55: 'Dachshund',\n",
       " 56: 'Dalmatian',\n",
       " 57: 'Dandie_dinmont_terrier',\n",
       " 58: 'Doberman_pinscher',\n",
       " 59: 'Dogue_de_bordeaux',\n",
       " 60: 'English_cocker_spaniel',\n",
       " 61: 'English_setter',\n",
       " 62: 'English_springer_spaniel',\n",
       " 63: 'English_toy_spaniel',\n",
       " 64: 'Entlebucher_mountain_dog',\n",
       " 65: 'Field_spaniel',\n",
       " 66: 'Finnish_spitz',\n",
       " 67: 'Flat-coated_retriever',\n",
       " 68: 'French_bulldog',\n",
       " 69: 'German_pinscher',\n",
       " 70: 'German_shepherd_dog',\n",
       " 71: 'German_shorthaired_pointer',\n",
       " 72: 'German_wirehaired_pointer',\n",
       " 73: 'Giant_schnauzer',\n",
       " 74: 'Glen_of_imaal_terrier',\n",
       " 75: 'Golden_retriever',\n",
       " 76: 'Gordon_setter',\n",
       " 77: 'Great_dane',\n",
       " 78: 'Great_pyrenees',\n",
       " 79: 'Greater_swiss_mountain_dog',\n",
       " 80: 'Greyhound',\n",
       " 81: 'Havanese',\n",
       " 82: 'Ibizan_hound',\n",
       " 83: 'Icelandic_sheepdog',\n",
       " 84: 'Irish_red_and_white_setter',\n",
       " 85: 'Irish_setter',\n",
       " 86: 'Irish_terrier',\n",
       " 87: 'Irish_water_spaniel',\n",
       " 88: 'Irish_wolfhound',\n",
       " 89: 'Italian_greyhound',\n",
       " 90: 'Japanese_chin',\n",
       " 91: 'Keeshond',\n",
       " 92: 'Kerry_blue_terrier',\n",
       " 93: 'Komondor',\n",
       " 94: 'Kuvasz',\n",
       " 95: 'Labrador_retriever',\n",
       " 96: 'Lakeland_terrier',\n",
       " 97: 'Leonberger',\n",
       " 98: 'Lhasa_apso',\n",
       " 99: 'Lowchen',\n",
       " 100: 'Maltese',\n",
       " 101: 'Manchester_terrier',\n",
       " 102: 'Mastiff',\n",
       " 103: 'Miniature_schnauzer',\n",
       " 104: 'Neapolitan_mastiff',\n",
       " 105: 'Newfoundland',\n",
       " 106: 'Norfolk_terrier',\n",
       " 107: 'Norwegian_buhund',\n",
       " 108: 'Norwegian_elkhound',\n",
       " 109: 'Norwegian_lundehund',\n",
       " 110: 'Norwich_terrier',\n",
       " 111: 'Nova_scotia_duck_tolling_retriever',\n",
       " 112: 'Old_english_sheepdog',\n",
       " 113: 'Otterhound',\n",
       " 114: 'Papillon',\n",
       " 115: 'Parson_russell_terrier',\n",
       " 116: 'Pekingese',\n",
       " 117: 'Pembroke_welsh_corgi',\n",
       " 118: 'Petit_basset_griffon_vendeen',\n",
       " 119: 'Pharaoh_hound',\n",
       " 120: 'Plott',\n",
       " 121: 'Pointer',\n",
       " 122: 'Pomeranian',\n",
       " 123: 'Poodle',\n",
       " 124: 'Portuguese_water_dog',\n",
       " 125: 'Saint_bernard',\n",
       " 126: 'Silky_terrier',\n",
       " 127: 'Smooth_fox_terrier',\n",
       " 128: 'Tibetan_mastiff',\n",
       " 129: 'Welsh_springer_spaniel',\n",
       " 130: 'Wirehaired_pointing_griffon',\n",
       " 131: 'Xoloitzcuintli',\n",
       " 132: 'Yorkshire_terrier'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary for class-to-label mapping\n",
    "\n",
    "test_path = os.path.join(local_dataset_path, \"test\")\n",
    "\n",
    "label_breed_mapping = {k:v.split(\".\")[1] for k, v in enumerate(os.listdir(test_path))}\n",
    "label_breed_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an prediction on the endpoint\n",
    "\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "\n",
    "test_folder = \"012.Australian_shepherd\"\n",
    "test_image = \"Australian_shepherd_00830.jpg\"\n",
    "\n",
    "with open(os.path.join(test_path, test_folder, test_image), \"rb\") as f:\n",
    "    image = f.read()\n",
    "response = predictor.predict(image)\n",
    "\n",
    "print(\"Expected label: \\\"{}\\\" with  index of {}\".format(\n",
    "      test_folder.split(\".\")[1],\n",
    "      test_folder.split(\".\")[0]))\n",
    "print(\"Predicted label: \\\"{}\\\" with index of {}\".format(\n",
    "    response,\n",
    "    label_breed_mapping[response]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IIPORTANT) Shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
